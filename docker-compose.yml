services:
  frontend:
    build:
      context: ./frontend 
    ports:
      - "5173:5173" 
    volumes:
      - ./frontend:/app 
      - /app/node_modules
    environment:
      - CHOKIDAR_USEPOLLING=true 
    command: npm run dev -- --host 

  question-service:
    build:
      context: ./backend/question-service
    ports:
      - "8080:8080"

  user-service:
    build:
      context: ./backend/user-service
    ports:
      - "8081:8081"

  matching-service:
    build:
      context: ./backend/matching-service
    ports:
      - "8082:8082"
    depends_on:
      - rabbitmq

  ai-service:
    build:
       context: ./backend/ai-service
    ports:
      - "9680:9680"
    depends_on:
      - ollama

  ollama:
    image: ollama/ollama:0.3.14
    volumes:
      - ollama:/root/.ollama
      # - ./backend/ai-service:/backend/ai-service
    ports:
      - "11434:11434"

    # entrypoint: ["/bin/sh", "/backend/ai-service/entrypoint.sh"]

  rabbitmq:
    image: "rabbitmq:3-management"
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      RABBITMQ_DEFAULT_USER: guest
      RABBITMQ_DEFAULT_PASS: guest
    attach: false

  code-execution-service:
    build:
      context: ./backend/code-execution-service
    ports:
      - "8083:8083"

  collaboration-service:
    build:
      context: ./backend/collaboration-service
    ports:
      - "8084:8084"

volumes:
  ollama:

# if using 1 env file in root folder (env.example is in google docs)

# services:
#   frontend:
#     build:
#       context: ./frontend
#     ports:
#       - "5173:5173"
#     volumes:
#       - ./frontend:/app
#       - /app/node_modules
#     command: npm run dev -- --host

#   question-service:
#     build:
#       context: ./backend/question-service
#     ports:
#       - "8080:8080"
#     env_file:
#       - ./.env 

#   user-service:
#     build:
#       context: ./backend/user-service
#     ports:
#       - "8081:8081"
#     env_file:
#       - ./.env

#   matching-service:
#     build:
#       context: ./backend/matching-service
#     ports:
#       - "8082:8082"
#     depends_on:
#       - rabbitmq
#     env_file:
#       - ./.env

#   ai-service:
#     image: "yongshikang/cs3219-ay2425s1-project-g26-ai-service:1.4"
#     ports:
#       - "9680:9680"
#     env_file:
#       - ./.env

#   rabbitmq:
#     image: "rabbitmq:3-management"
#     ports:
#       - "5672:5672"
#       - "15672:15672"
#     environment:
#       RABBITMQ_DEFAULT_USER: ${RABBITMQ_DEFAULT_USER}
#       RABBITMQ_DEFAULT_PASS: ${RABBITMQ_DEFAULT_PASS}
#     env_file:
#       - ./.env

#   code-execution-service:
#     build:
#       context: ./backend/code-execution-service
#     ports:
#       - "8083:8083"
#     env_file:
#       - ./.env

#   collaboration-service:
#     build:
#       context: ./backend/collaboration-service
#     ports:
#       - "8084:8084"
#     env_file:
#       - ./.env
